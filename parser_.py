from ply import lex

class Node:
    def __init__(self, type, value=None):
        self.type = type
        self.value = value
        self.children = []

# Token list
tokens = (
    'NUMBER',
    'PLUS',
    'MINUS',
    'TIMES',
    'DIVIDE',
    'LPAREN',
    'RPAREN'
)

# Regular expressions for tokens
t_PLUS = r'\+'
t_MINUS = r'-'
t_TIMES = r'\*'
t_DIVIDE = r'/'
t_LPAREN = r'\('
t_RPAREN = r'\)'

# Ignore whitespace
t_ignore = ' \t'

def t_NUMBER(t):
    r'\d+'
    t.value = int(t.value)
    return t

# Error handling rule
def t_error(t):
    print("Illegal character '%s'" % t.value[0])
    t.lexer.skip(1)

# Build the lexer
lexer = lex.lex()

# Parsing rules
def p_expression_plus(p):
    'expression : expression PLUS term'
    p[0] = p[1] + p[3]

def p_expression_minus(p):
    'expression : expression MINUS term'
    p[0] = p[1] - p[3]

def p_expression_term(p):
    'expression : term'
    p[0] = p[1]

def p_term_times(p):
    'term : term TIMES factor'
    p[0] = p[1] * p[3]

def p_term_divide(p):
    'term : term DIVIDE factor'
    p[0] = p[1] / p[3]

def p_term_factor(p):
    'term : factor'
    p[0] = p[1]

def p_factor_num(p):
    'factor : NUMBER'
    p[0] = p[1]

def p_factor_expr(p):
    'factor : LPAREN expression RPAREN'
    p[0] = p[2]

def p_error(p):
    print("Syntax error in input!")

# Build the parser
def tokenize_expression(expression):
    lexer.input(expression)
    tokens = []
    for tok in lexer:
        tokens.append((tok.type, tok.value))
    return tokens
  
def parse_tokens(tokens):
    """
    Parses the tokens into an Abstract Syntax Tree (AST).

    Args:
    - tokens: List of tokens generated by the lexer.

    Returns:
    - Root node of the AST.
    """
    # Define operator precedence
    precedence = {
        'TIMES': 2,
        'DIVIDE': 2,
        'PLUS': 1,
        'MINUS': 1,
        'LPAREN': 0,
        'RPAREN': 0
    }

    output = []
    operator_stack = []

    for token_type, token_value in tokens:
        if token_type == 'NUMBER':
            output.append(Node('NUMBER', token_value))
        elif token_type in ['PLUS', 'MINUS', 'TIMES', 'DIVIDE']:
            while (operator_stack and precedence[operator_stack[-1].type] >= precedence[token_type]):
                output.append(operator_stack.pop())
            operator_stack.append(Node(token_type))
        elif token_type == 'LPAREN':
            operator_stack.append(Node(token_type))
        elif token_type == 'RPAREN':
            while operator_stack[-1].type != 'LPAREN':
                output.append(operator_stack.pop())
            operator_stack.pop()  # Remove the '('

    while operator_stack:
        output.append(operator_stack.pop())

    # Construct the AST
    stack = []
    for item in output:
        if item.type in ['PLUS', 'MINUS', 'TIMES', 'DIVIDE']:
            right = stack.pop()
            left = stack.pop()
            item.children.extend([left, right])
            stack.append(item)
        else:
            stack.append(item)

    return stack[0]